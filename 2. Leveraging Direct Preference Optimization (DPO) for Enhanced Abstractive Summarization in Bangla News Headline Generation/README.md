<div align="justify">
This project focused on Bangla news headline generation using Direct Preference Optimization (DPO) for abstractive summarization. The approach involved creating a preference dataset from Kaggle's Bangla summarization data, followed by fine-tuning the LLaMA-3.2-1B model using supervised learning and DPO to prioritize better headline generation. The model was trained to produce concise, human-like headlines with strong contextual alignment, and performance was evaluated using BLEU scores and visual comparisons. This work demonstrated the potential of DPO for improving text generation in Bangla, with plans for future extensions to Bangla-specific LLMs and real-time feedback integration. 
</div>


Presentation Video Link: https://youtu.be/U_AZO6fYgEE?si=cfif947Cjn9OIihN
