With the growing use of AI-driven communication, large language models (LLMs) have become popular tools for automated email generation. However, these models are typically unaware of how spam filters operate, often generating content that inadvertently contains spam-triggering words or patterns. As a result, even legitimate emails, such as job applications or scholarship offers, are frequently misclassified as spam. This misclassification can result in missed opportunities and communication failures. This work proposes an efficient approach for generating professional, non-spam emails based on finetuning an LLM. In order to avoid spam-triggering patterns, supervised fine-tuning (SFT) approach has been incorporated in the proposed method, along with parameter efficient finetuning (PEFT) techniques. Here to optimize the pre-trained models, GPT-2 and Mistral-7B models are chosen. From extensive simulations, it is found that the proposed fine-tuned models outperform base models in generating contextually appropriate emails that are less likely to be flagged as spam. The proposed scheme is applicable to both simple and advanced LLMs and can be extended to other targeted text generation tasks. 
